{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Basic Regression\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Simple Linear Regression\n",
    "\n",
    "Looks for a linear relationship between predictor and response.\n",
    "\n",
    "$y = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_m x_m$\n",
    "\n",
    "$= \\beta_0 + \\sum_{j=1}^{m} \\beta_j x_j$\n",
    "\n",
    "The total error can be presented as a sum of squared errors (SSE):\n",
    "\n",
    "$\\sum_{i=1}^{n} (y_i - \\hat y_i)^2 = \\sum_{i=1}^{n} (y_i - (\\beta_0 + \\beta \\cdot x_i))^2$\n",
    "\n",
    "where $x_i$ is a vector of one observation\n",
    "\n",
    "The best fit regression line minimizes the sum of squared errors as defined by $\\beta$. The sum of squared errors is a concave up (convex) quadratic function and therefore we can find its minimum by setting its derivative to zero. \n",
    "\n",
    "To find the value of each $\\beta_j$ where SSE is at its minimum, then we set partial derivatives with respect to $\\beta_j$ to zero and solve the simultaneous equations.\n",
    "\n",
    "****\n",
    "\n",
    "## Measuring the qualify of a model's fit\n",
    "\n",
    "**Maximum Likelihood Estimation (MLE)**\n",
    "\n",
    "The most basic measure of a model's quality is **likelihood**, i.e. \n",
    "given an estimated set of model parameters, $\\theta$, what is the likelihood of witnessing these observations under this set of parameters?\n",
    "\n",
    "$P(X | \\theta)$ is the likelihood function where $X$ is the observed data and $\\theta$ is the model's parameters. Given a search through all parameter sets, we select the set that returns the maximum likelihood.\n",
    "\n",
    "*Example*\n",
    "\n",
    "Suppose we have a model which have estimates $y_1, \\dots, y_n$, and observations $z_1, \\dots, z_n$ then the errors should be normally distributed with an expectation of zero such that $\\epsilon \\sim N(0,\\sigma^2)$, i.i.d.\n",
    "\n",
    "Then, the probability density or likelihood function for a single observation will be:\n",
    "\n",
    "$P(X_i | \\theta) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\cdot e^{-\\frac{(z_i-y_i)^2}{2 \\sigma^2}}$\n",
    "\n",
    "The joint density of all observations is then a product of the above:\n",
    "\n",
    "$P(X | \\theta) = \\prod_{i=1}^{n} \\frac{1}{\\sigma \\sqrt{2\\pi}} \\cdot e^{-\\frac{(z_i-y_i)^2}{2 \\sigma^2}}$\n",
    "\n",
    "$= (\\frac{1}{\\sigma \\sqrt{2\\pi}})^n \\cdot e^{-\\frac{1}{2 \\sigma^2}\\sum_{i=1}^{n} (z_i-y_i)^2}$\n",
    "\n",
    "$\\theta$ is picked such that it maximizes the likelihood and is equivalent to minimizing the sum of squared errors, such that\n",
    "\n",
    "$\\max (\\frac{1}{\\sigma \\sqrt{2\\pi}})^n \\cdot e^{-\\frac{1}{2 \\sigma^2}\\sum_{i=1}^{n} (z_i-y_i)^2} \\to \\min \\sum_{i=1}^{n} (z_i - y_i)^2$\n",
    "\n",
    "$\\therefore$ Minimizing the sum of squared errors ensures that maximum likelihood is achieved.\n",
    "\n",
    "Likelihood can also be used to compare two different models by using the likelihood ratio test and applying a hypothesis test.\n",
    "\n",
    "****\n",
    "\n",
    "**Akaike Information Criterion (AIC)**\n",
    "\n",
    "Helps to balance the model's likelihood ($L^*$) and its simplicity ($k$, # of parameters).\n",
    "\n",
    "$\\text{AIC} = 2k - 2\\ln(L^*)$\n",
    "\n",
    "where the penalty term, $2k$ helps to avoid overfitting by balancing likelihood and simplicity.\n",
    "\n",
    "Models with smaller AIC are preferred and therefore encourages fewer parameters $k$ while maximizing likelihood.\n",
    "\n",
    "The classical AIC works well when there are infinitely many data points, but a corrected version of AIC can be applied to smaller data sets:\n",
    "\n",
    "$AIC_c = AIC + \\frac{2k(k+1)}{n-k-1} = 2k - 2\\ln(L^*) + \\frac{2k(k+1)}{n-k-1}$\n",
    "\n",
    "We can also compare the AIC scores of two different models and compute its relative likelihood, with an example as follows:\n",
    "\n",
    "- Model 1 with $AIC = 75$ vs Model 2 with $AIC = 80$\n",
    "- The relative likelihood is characterized as:\n",
    "\n",
    "    $e^{\\frac{(AIC_1 - AIC_2)}{2}} = e^{\\frac{(75 - 80)}{2}}  \\approx 8.2\\%$\n",
    "    \n",
    "    $\\therefore$ Model 2 is only 8.2% likely to be a better model than Model 1 and thus the first model is probably better\n",
    "    \n",
    "    \n",
    "A similar criterion, BIC, Bayesian Information Criterion, is a harsher version of AIC and ha a stronger penalty term. Typically BIC is only used when there are more data points than parameters.\n",
    "\n",
    "$AIC = 2k - 2\\ln(L^*)$\n",
    "\n",
    "$BIC = k \\ln (n) - 2\\ln(L^*)$\n",
    "\n",
    "where $k \\ln (n) > 2k$ generally and therefore BIC encourages simpler models than AIC does\n",
    "\n",
    "****\n",
    "\n",
    "## Generalized Linear Models\n",
    "\n",
    "Relationships between two variables may not always be linear but we can transform our data such that the fit becomes linear.\n",
    "\n",
    "<img alt=\"Non-linear Relationships\" src=\"assets/non_linear_relationship.png\" width=\"500\" >\n",
    "\n",
    "Here are some possible ways of transformations:\n",
    "\n",
    "- Quadratic regression: $y = a_0 + a_1 x_1 + a_2 x_1^2$\n",
    "- Response transform: $\\log(y) = a_0 + a_1 x_1 + \\dots + a_m x_m$\n",
    "- Box-Cox transformations\n",
    "- Variable interactions: $y = a_0 + a_1 x_1 + a_2 x_2 + a_3 x_1 x_2$\n",
    "\n",
    "****\n",
    "\n",
    "**Box-Cox Transformation**\n",
    "\n",
    "****\n",
    "\n",
    "**De-trending data**\n",
    "\n",
    "****\n",
    "\n",
    "## Principal Components Analysis (PCA)\n",
    "\n",
    "****\n",
    "\n",
    "**Interpreting regression coefficients in PCA**\n",
    "\n",
    "****\n",
    "\n",
    "**Eigenvalues and eigenvectors**\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic code\n",
    "A `minimal, reproducible example`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
