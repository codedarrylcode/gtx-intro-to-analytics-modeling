{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance Norms\n",
    "\n",
    "Here we explore the necessary distance norms and how it would relate to clustering.\n",
    "\n",
    "1. *Euclidean Distance (straight-line)*\n",
    "\n",
    "    $distance = \\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}$\n",
    "\n",
    "\n",
    "2. *Manhattan Distance (rectilinear)*\n",
    "\n",
    "    $distance = \\vert x_2 - x_1 \\vert + \\vert y_2 - y_2 \\vert$\n",
    "    \n",
    "    \n",
    "3. *Minkowski Distance (p-norm distance)*\n",
    "\n",
    "    $distance = \\sqrt[p]{\\vert x_2 - x_1 \\vert^p + \\vert y_2 - y_2 \\vert^p}$\n",
    "    \n",
    "\n",
    "The third most common $p$ to use in calculating distances would be $\\infty$ such that it is the $\\infty$-norm distance. The intuition for such common use is as follows:\n",
    "\n",
    "$\\vert x_2 - x_1 \\vert^{\\infty} + \\vert y_2 - y_1 \\vert^{\\infty} + \\dots$\n",
    "\n",
    "The term that will dominate the distance measure is the $\\max \\vert x_{n+1} - x_{n} \\vert^{\\infty}$ which means that the measure will be defined by the largest (absolute) set of all distances, i.e. it doesn't matter how large the other distances are and the only one that matters is the largest distance (*bottlenecks as examples*).\n",
    "\n",
    "****\n",
    "\n",
    "## K-Means\n",
    "\n",
    "Given a dataset, $X \\in \\mathbb{R}^d$, then the algorithm is as follows:\n",
    "\n",
    "$\\min_{y, z} \\sum_i \\sum_k y_{ik} \\cdot \\sqrt{\\sum_j (x_{ij} - z_{jk})^2}$\n",
    "\n",
    "where\n",
    "\n",
    "- $x_{ij}$ is the attribute $j$ of data point $i$\n",
    "- $y_{ik}$ is the assignment of data point $i$ to cluster $k$ (binary)\n",
    "- $z_{jk}$ is the coordinate $j$ of cluster center $k$\n",
    "\n",
    "subject to $\\sum_k y_{ik} = 1$ such that each data point can only belong to one cluster at each iteration\n",
    "\n",
    "*Procedure*:\n",
    "\n",
    "1. Initialize $k$ cluster centers randomly\n",
    "2. Temporarily assign each data point to nearest cluster center\n",
    "3. Recalculate cluster centers (*Expectation*)\n",
    "4. Reassigns each data point to nearest cluster center (*Maximization*)\n",
    "5. Repeat until convergence\n",
    "\n",
    "The algorithm is an expectation-maximization algorithm and is often referred to as a heuristic that is fast but not guaranteed to find the global optima and does a hard assignemnt of data points to clusters.\n",
    "\n",
    "*Practical tips*:\n",
    "\n",
    "- Not robust to outliers, need to address outlying data points before running algorithm\n",
    "- Try running several times with different initial cluster centers and choose the best solution (*distance is minimized*)\n",
    "- Test different values of $k$ clusters and pick $k$ such that the second derivative of total distances vs # of clusters is at zero \n",
    "\n",
    "<img alt=\"Elbow Method\" src=\"assets/elbow_method.png\" width=\"400\" >\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic code\n",
    "A `minimal, reproducible example`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
