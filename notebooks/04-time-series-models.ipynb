{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Models\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponential Smoothing\n",
    "\n",
    "Randomness (*or random variation*) naturally exists and exponential smoothing can help to manage that.\n",
    "\n",
    "Suppose $S_t$ is the expected baseline response at time period $t$ and $x_t$ is the observed response. What is the real response over time without variation? Is there a real increase in baseline or is this a random event?\n",
    "\n",
    "Two ways to answer:\n",
    "\n",
    "- $S_t = x_t$\n",
    "- $S_t = S_{t-1}$\n",
    "\n",
    "The exponential smoothing method combines both such that $S_t = \\alpha x_t + (1-\\alpha) S_{t-1}$ where $0 < \\alpha < 1$ and is essentially a weighted average between the observation and the previous baseline, controlled by $\\alpha$, such that: \n",
    "\n",
    "- $\\alpha \\to 0$: a lot of randomness in the system\n",
    "- $\\alpha \\to 1$: not much randomness in the system where the current reading is the best predictor\n",
    "\n",
    "But this basic equation does not deal with trends or cyclical variations.\n",
    "\n",
    "****\n",
    "\n",
    "**Dealing with trends and cyclic effects**\n",
    "\n",
    "- *Trend patterns*\n",
    "\n",
    "    Suppose $T_t$ is the trend at a time period $t$ then we can modify the exponential smoothing method to the following:\n",
    "\n",
    "    $S_t = \\alpha x_t + (1-\\alpha) (S_{t-1} + T_{t-1})$\n",
    "    \n",
    "    This adjusts for trend as an additive component to the original formula.\n",
    "\n",
    "    We can compute $T_t$ as an weighted average, controlled by $\\beta$, such that:\n",
    "\n",
    "    $T_t = \\beta (S_t - S_{t-1}) + (1 - \\beta) T_{t-1}$ with an initial condition of $T_1 = 0$\n",
    "\n",
    "    \n",
    "- *Cyclic/seasonal patterns*\n",
    "\n",
    "    In adjusting for seasonality, we can approach this with a multiplicative way:\n",
    "    \n",
    "    $S_t = \\frac{\\alpha x_t}{C_{t-L}} + (1-\\alpha) (S_{t-1} + T_{t-1})$, i.e. *Holt-Winters method*\n",
    "    \n",
    "    where:\n",
    "    - $L$: the length of a cycle\n",
    "    - $C_t$: the multiplicative seasonality factor for time $t$ to inflate or deflate the observation\n",
    "    \n",
    "    To compute $C_t$, we can update the seasonal/cyclic factor in a similar way:\n",
    "    \n",
    "    $C_t = \\gamma (\\frac{x_t}{S_t}) + (1 - \\gamma) (C_{t-L})$\n",
    "    \n",
    "    where the initial $C_1, \\dots, C_L = 1$\n",
    "\n",
    "****\n",
    "\n",
    "**Forecasting**\n",
    "\n",
    "Suppose $F_{t+1}$ is our forecast for one time unit ahead and our prediction follows:\n",
    "\n",
    "- Forecasting with basic exponential smoothing\n",
    "\n",
    "    $F_{t+1} = \\alpha S_t + (1-\\alpha) S_t$\n",
    "    \n",
    "    since our best guess for $x_{t+1} = S_t$\n",
    "    \n",
    "    $\\therefore F_{t+1} = S_t$\n",
    "    \n",
    "    \n",
    "- Forecasting with trend (additive)\n",
    "\n",
    "    $S_t = \\alpha x_t + (1-\\alpha) (S_{t-1} + T_{t-1})$\n",
    "    \n",
    "    $T_t = \\beta (S_t - S_{t-1}) + (1-\\beta) T_{t-1}$\n",
    "\n",
    "    $\\therefore F_{t+1} = S_t + T_t$\n",
    "    \n",
    "    This generalizes to the next periods as we assume the current trend is our best guess for future trend.\n",
    "    \n",
    "    $F_{t+k} = S_t + k \\cdot T_t$ where $k = 1, 2, \\dots$\n",
    "    \n",
    "    \n",
    "- Forecasting with seasonality (multiplicative)\n",
    "\n",
    "    $S_t = \\frac{\\alpha x_t}{C_{t-L}} + (1-\\alpha) (S_{t-1} + T_{t-1})$\n",
    "    \n",
    "    The best estimate of the next time period's seasonal factor will be:\n",
    "    \n",
    "    $C_{t+1} = C_{(t+1)-L}$\n",
    "    \n",
    "    $\\therefore$ Our forecast for time period $t+1$ will be:\n",
    "    \n",
    "    $F_{t+1} = (S_t + T_t) \\cdot C_{(t+1)-L}$\n",
    "    \n",
    "    \n",
    "To find the best values of $\\alpha, \\beta, \\gamma$ is the optimal set of parameters that minimizes the bias between forecast and observation, $(F_t - x_t)^2$\n",
    "\n",
    "****\n",
    "\n",
    "## ARIMA\n",
    "\n",
    "*Autoregressive integrated moving average*\n",
    "\n",
    "Three key parts:\n",
    "\n",
    "1. **Differences**\n",
    "\n",
    "    - Exponential smoothing basic equation: $S_t = \\alpha x_t + (1-\\alpha) S_{t-1}$\n",
    "    - $S_t = \\alpha x_t + (1-\\alpha) S_{t-1} + (1-\\alpha)^2 \\alpha x_{t-2} + \\dots$\n",
    "        - Estimates $S_t$ based on $x_t, x_{t-1}$, etc.\n",
    "        - Works well when data is *stationary, i.e. if the mean, variance, and other measures are all expected to be constant over time*\n",
    "    - Often, data is not stionary but the differences might be stationary:\n",
    "        - First-order difference, $D_1$: difference of consecutive observations such that, $D_1 = (x_t - x_{t-1})$\n",
    "        - Second-order difference, $D_2$: difference of the differences, such that, $D_2 = (x_t - x_{t-1}) - (x_{t-1} - x_{t-2})$\n",
    "        - $d$th-order differences\n",
    "  \n",
    "  \n",
    "2. **Autoregression**\n",
    "\n",
    "    - Predicting the current value based on previous time periods' values, i.e. using earlier values to predict current value\n",
    "    - Order-$p$ autoregressive model: $S_t$ is a function of $\\{ x_t, x_{t-1}, \\dots, x_{t-(p-1)}\\}$\n",
    "    \n",
    "\n",
    "3. **Moving Average**\n",
    "\n",
    "    - Using previous errors as predictors, $\\epsilon_t = (\\bar x_t - x_t)$, i.e. the predicted value minus the observed value is the error\n",
    "    - Order-$q$ moving average goes back $q$ time periods, $\\epsilon_{t-1}, \\dots, \\epsilon_{t-q}$\n",
    "    \n",
    "****\n",
    "    \n",
    "**Putting it altogether**\n",
    "\n",
    "The ARIMA model has three parameters, $p, d, q$ and can be represented as $\\text{ARIMA(p,d,q)}$, such that:\n",
    "\n",
    "$D_{(d)t} = \\mu + \\sum_{i=1}^{p} \\alpha_i D_{(d)t - i} - \\sum_{i=1}^{q} \\theta_i (\\bar x_{t-i} - x_{t-i})$\n",
    "\n",
    "where\n",
    "\n",
    "- $D_{(d)t}$ is the differenced value at time $t$\n",
    "- $\\mu$ is the mean value of the stationary distribution\n",
    "- The second term being the autoregressive part based on differenced terms\n",
    "- The last term being the moving average part based on previous errors\n",
    "\n",
    "\n",
    "The parameters $p, d, q$ can be optimized for the best fit to the data. Different values of $p, d, q$ can represent different types of models:\n",
    "\n",
    "- $\\text{ARIMA(0,0,0)}$ is a white noise model\n",
    "- $\\text{ARIMA(0,1,0)}$ is a random walk model\n",
    "- $\\text{ARIMA(p,0,0)}$ is an AR (autoregressive) model\n",
    "- $\\text{ARIMA(0,0,q)}$ is a moving average model\n",
    "- $\\text{ARIMA(0,1,1)}$ is an exponential smoothing model\n",
    "\n",
    "It is best used for short-term forecasting and is better than exponential smoothing when the data is more stable, with fewer peaks/valleys and outliers. A rule of thumb requires ~40 data points for ARIMA to work well.\n",
    "\n",
    "****\n",
    "\n",
    "## GARCH\n",
    "*Generalized Autoregressive Conditional Heteroskedasticity*\n",
    "\n",
    "One common way to estimate variance on time-series is to use *GARCH*, which is structurally similar to the ARIMA model.\n",
    "\n",
    "$\\sigma_t^2 = \\omega + \\sum_{i=1}^{p} \\beta_i \\sigma_{t-i}^2 + \\sum_{i=1}^{q} \\gamma_i \\epsilon_{t-i}^2$\n",
    "\n",
    "Two differences from ARIMA:\n",
    "\n",
    "1. Estimates variances/squared errors, not observations or linear errors\n",
    "2. Estimates raw variances and not differences of variances\n",
    "    \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic code\n",
    "A `minimal, reproducible example`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T08:08:55.383587Z",
     "start_time": "2022-02-14T08:08:55.377901Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
